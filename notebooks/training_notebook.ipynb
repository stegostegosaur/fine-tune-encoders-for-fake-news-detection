{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning a Transformer for Fake News Detection\n",
    "\n",
    "This notebook contains the complete pipeline for fine-tuning a transformer model (like BERT or DistilBERT) for text classification, based on the `train.py` script. The process includes:\n",
    "\n",
    "1.  **Configuration**: Setting up all experiment parameters.\n",
    "2.  **Helper Functions**: Defining logic for layer freezing and metrics computation.\n",
    "3.  **Data Loading & Preparation**: Loading the processed dataset and creating a validation split.\n",
    "4.  **Tokenization**: Preparing the text data for the model.\n",
    "5.  **Model Setup**: Loading the model and applying the layer freezing strategy.\n",
    "6.  **Training**: Running the fine-tuning process using the Hugging Face `Trainer`.\n",
    "7.  **Saving & Pushing to Hub**: Saving the final model and optionally pushing it to the Hugging Face Hub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    HfFolder,\n",
    "    notebook_login,\n",
    ")\n",
    "from datasets import Dataset, DatasetDict\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# Setup logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer Freezing Logic\n",
    "\n",
    "This function applies the chosen freezing strategy ('all', 'half', or 'none') to the model's encoder layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_layers(model, model_type, freeze_mode, num_total_layers_bert=12, num_total_layers_distilbert=6):\n",
    "    logger.info(f\"Applying freeze mode: {freeze_mode} for model type: {model_type}\")\n",
    "    if freeze_mode == \"none\": # Full fine-tuning\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True\n",
    "        logger.info(\"All layers are trainable (full fine-tuning).\")\n",
    "        return\n",
    "\n",
    "    if model_type == 'bert':\n",
    "        encoder_layers = model.bert.encoder.layer\n",
    "        embeddings = model.bert.embeddings\n",
    "        num_total_layers = num_total_layers_bert\n",
    "    elif model_type == 'distilbert':\n",
    "        encoder_layers = model.distilbert.transformer.layer\n",
    "        embeddings = model.distilbert.embeddings\n",
    "        num_total_layers = num_total_layers_distilbert\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model type: {model_type}\")\n",
    "\n",
    "    # Freeze embeddings by default when freezing encoder layers\n",
    "    logger.info(\"Freezing embedding layers.\")\n",
    "    for param in embeddings.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    if freeze_mode == \"all\":\n",
    "        num_layers_to_freeze = num_total_layers\n",
    "    elif freeze_mode == \"half\":\n",
    "        num_layers_to_freeze = num_total_layers // 2\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported freeze mode: {freeze_mode}. Choose 'all', 'half', or 'none'.\")\n",
    "\n",
    "    logger.info(f\"Total encoder layers: {num_total_layers}. Layers to freeze: {num_layers_to_freeze}.\")\n",
    "\n",
    "    for i, layer in enumerate(encoder_layers):\n",
    "        if i < num_layers_to_freeze:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = False\n",
    "        else:\n",
    "            for param in layer.parameters(): # Ensure subsequent layers are trainable\n",
    "                param.requires_grad = True\n",
    "    \n",
    "    # Ensure the classifier head is always trainable\n",
    "    trainable_classifier = False\n",
    "    if hasattr(model, 'classifier') and model.classifier is not None:\n",
    "        for param in model.classifier.parameters():\n",
    "            param.requires_grad = True\n",
    "        trainable_classifier = True\n",
    "    if hasattr(model, 'pre_classifier') and model.pre_classifier is not None: # For DistilBERT\n",
    "         for param in model.pre_classifier.parameters():\n",
    "            param.requires_grad = True\n",
    "         trainable_classifier = True\n",
    "    \n",
    "    if trainable_classifier:\n",
    "        logger.info(\"Classifier head parameters are set to trainable.\")\n",
    "    else:\n",
    "        logger.warning(\"Could not find a standard classifier head to ensure it's trainable.\")\n",
    "\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    logger.info(f\"Number of trainable parameters: {trainable_params} / {total_params} ({100 * trainable_params / total_params:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics Computation\n",
    "\n",
    "This function calculates accuracy, F1-score, precision, and recall. It will be passed to the `Trainer` to evaluate the model on the validation set during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    \n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average='weighted')\n",
    "    precision = precision_score(labels, preds, average='weighted')\n",
    "    recall = recall_score(labels, preds, average='weighted')\n",
    "    \n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuration\n",
    "\n",
    "Instead of command-line arguments, we define all parameters in this configuration class. **This is the main place to change settings for different experiments.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingConfig:\n",
    "    # --- Model arguments ---\n",
    "    # Change for different experiments: 'distilbert-base-uncased' or 'bert-base-uncased'\n",
    "    model_name_or_path = \"distilbert-base-uncased\"\n",
    "    # Must match model_name_or_path: 'distilbert' or 'bert'\n",
    "    model_type = \"distilbert\" \n",
    "    # Change for different experiments: 'all', 'half', or 'none'\n",
    "    freeze_mode = \"half\" \n",
    "\n",
    "    # --- Data arguments ---\n",
    "    # Note: Paths are relative to the `notebooks` directory\n",
    "    train_file = \"../data/processed/train.csv\"\n",
    "    eval_file = None # Set to \"../data/processed/test.csv\" or other if you have a separate eval file\n",
    "    text_column = \"text\"\n",
    "    label_column = \"label\"\n",
    "    validation_split_size = 0.1 # Used if eval_file is None\n",
    "\n",
    "    # --- Training arguments ---\n",
    "    # Note: Paths are relative to the `notebooks` directory\n",
    "    output_dir = f\"../results/{model_type}_{freeze_mode}_notebook\"\n",
    "    num_train_epochs = 3\n",
    "    per_device_train_batch_size = 8\n",
    "    per_device_eval_batch_size = 16\n",
    "    learning_rate = 5e-5\n",
    "    weight_decay = 0.01\n",
    "    warmup_steps = 0\n",
    "    logging_steps = 100\n",
    "    eval_steps = 500 # Used if evaluation_strategy is 'steps'\n",
    "    save_steps = 500 # Used if save_strategy is 'steps'\n",
    "    evaluation_strategy = \"epoch\"\n",
    "    save_strategy = \"epoch\"\n",
    "    load_best_model_at_end = True\n",
    "    metric_for_best_model = \"f1\"\n",
    "    fp16 = torch.cuda.is_available() # Enable if you have a compatible GPU\n",
    "\n",
    "    # --- Hugging Face Hub arguments ---\n",
    "    push_to_hub = False # Set to True to push model to the Hub\n",
    "    # IMPORTANT: Change this to your username and a descriptive model name\n",
    "    hub_model_id = f\"your-username/{model_type}-{freeze_mode}-fakern\"\n",
    "    hub_token = None # Will use token from `notebook_login` or saved token\n",
    "\n",
    "# Instantiate the config\n",
    "args = TrainingConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hugging Face Hub Login\n",
    "\n",
    "If `push_to_hub` is set to `True` in the config, this cell will prompt you to log in to the Hugging Face Hub. You'll need to provide an access token with `write` permissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.push_to_hub:\n",
    "    logger.info(\"Attempting to log into Hugging Face Hub...\")\n",
    "    hub_token_to_use = args.hub_token or HfFolder.get_token()\n",
    "    if hub_token_to_use:\n",
    "        logger.info(\"Token found, will use it for pushing to Hub.\")\n",
    "    else:\n",
    "        logger.info(\"Hub token not found. Running notebook_login().\")\n",
    "        notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load and Prepare Data\n",
    "\n",
    "This section loads the training data from the specified CSV file. If no evaluation file is provided, it will automatically split the training data to create a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"Loading training data from: {args.train_file}\")\n",
    "train_df = pd.read_csv(args.train_file)\n",
    "\n",
    "if args.eval_file:\n",
    "    logger.info(f\"Loading evaluation data from: {args.eval_file}\")\n",
    "    eval_df = pd.read_csv(args.eval_file)\n",
    "    raw_datasets = DatasetDict({\n",
    "        'train': Dataset.from_pandas(train_df),\n",
    "        'validation': Dataset.from_pandas(eval_df)\n",
    "    })\n",
    "else:\n",
    "    logger.info(f\"No evaluation file provided. Splitting training data for validation (split: {args.validation_split_size}).\")\n",
    "    train_pandas_df, eval_pandas_df = train_test_split(\n",
    "        train_df, \n",
    "        test_size=args.validation_split_size, \n",
    "        random_state=42, \n",
    "        stratify=train_df[args.label_column] if args.label_column in train_df.columns else None\n",
    "    )\n",
    "    raw_datasets = DatasetDict({\n",
    "        'train': Dataset.from_pandas(train_pandas_df),\n",
    "        'validation': Dataset.from_pandas(eval_pandas_df)\n",
    "    })\n",
    "\n",
    "logger.info(f\"Raw datasets loaded: {raw_datasets}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Labels\n",
    "\n",
    "The model requires integer labels. We find all unique labels in our data and create `label2id` and `id2label` mappings, which are essential for both training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = train_df[args.label_column].unique()\n",
    "label2id = {label: i for i, label in enumerate(sorted(unique_labels))}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "num_labels = len(unique_labels)\n",
    "\n",
    "logger.info(f\"Found {num_labels} unique labels: {unique_labels}. Label mapping: {label2id}\")\n",
    "\n",
    "def map_labels(example):\n",
    "    example[args.label_column] = label2id[example[args.label_column]]\n",
    "    return example\n",
    "\n",
    "raw_datasets = raw_datasets.map(map_labels, batched=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Tokenization\n",
    "\n",
    "We load the tokenizer that corresponds to our chosen model and apply it to our datasets. This converts the text into a format the model can understand (token IDs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"Loading tokenizer for: {args.model_name_or_path}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(args.model_name_or_path)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[args.text_column], padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "logger.info(\"Tokenizing datasets...\")\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True, remove_columns=[args.text_column] if args.text_column in raw_datasets['train'].column_names else None)\n",
    "\n",
    "# The Trainer expects the label column to be named 'labels'\n",
    "if args.label_column != 'labels':\n",
    "     tokenized_datasets = tokenized_datasets.rename_column(args.label_column, \"labels\")\n",
    "\n",
    "logger.info(f\"Tokenized datasets ready: {tokenized_datasets}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Setup\n",
    "\n",
    "Now we load the pre-trained model. We provide `num_labels`, `id2label`, and `label2id` so it initializes with a classification head tailored to our specific task. Afterwards, we apply our chosen layer freezing strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"Loading model: {args.model_name_or_path} for {num_labels}-class classification.\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    args.model_name_or_path, \n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "# --- Apply Layer Freezing ---\n",
    "if args.freeze_mode != 'none':\n",
    "    freeze_layers(model, args.model_type, args.freeze_mode)\n",
    "else:\n",
    "    logger.info(\"No layer freezing applied (full fine-tuning). All model parameters are trainable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training\n",
    "\n",
    "Finally, we define the `TrainingArguments` and instantiate the `Trainer`. The `trainer.train()` call will start the fine-tuning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(args.output_dir, exist_ok=True)\n",
    "\n",
    "training_args_dict = {\n",
    "    \"output_dir\": args.output_dir,\n",
    "    \"num_train_epochs\": args.num_train_epochs,\n",
    "    \"per_device_train_batch_size\": args.per_device_train_batch_size,\n",
    "    \"per_device_eval_batch_size\": args.per_device_eval_batch_size,\n",
    "    \"learning_rate\": args.learning_rate,\n",
    "    \"weight_decay\": args.weight_decay,\n",
    "    \"warmup_steps\": args.warmup_steps,\n",
    "    \"logging_dir\": os.path.join(args.output_dir, 'logs'),\n",
    "    \"logging_steps\": args.logging_steps,\n",
    "    \"evaluation_strategy\": args.evaluation_strategy if 'validation' in tokenized_datasets else \"no\",\n",
    "    \"save_strategy\": args.save_strategy,\n",
    "    \"save_steps\": args.save_steps,\n",
    "    \"load_best_model_at_end\": args.load_best_model_at_end if 'validation' in tokenized_datasets else False,\n",
    "    \"metric_for_best_model\": args.metric_for_best_model if 'validation' in tokenized_datasets else None,\n",
    "    \"greater_is_better\": True if args.metric_for_best_model in [\"accuracy\", \"f1\"] else None,\n",
    "    \"fp16\": args.fp16,\n",
    "    \"report_to\": \"tensorboard\",\n",
    "}\n",
    "if args.push_to_hub:\n",
    "    training_args_dict[\"push_to_hub\"] = True\n",
    "    training_args_dict[\"hub_model_id\"] = args.hub_model_id\n",
    "    if args.hub_token:\n",
    "         training_args_dict[\"hub_token\"] = args.hub_token\n",
    "\n",
    "training_arguments = TrainingArguments(**training_args_dict)\n",
    "\n",
    "# --- Instantiate Trainer ---\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_arguments,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets.get(\"validation\"),\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics if tokenized_datasets.get(\"validation\") else None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Starting model training...\")\n",
    "\n",
    "try:\n",
    "    train_result = trainer.train()\n",
    "    trainer.save_model()  # Saves the tokenizer too\n",
    "    logger.info(\"Training finished successfully.\")\n",
    "\n",
    "    metrics = train_result.metrics\n",
    "    trainer.log_metrics(\"train\", metrics)\n",
    "    trainer.save_metrics(\"train\", metrics)\n",
    "    trainer.save_state()\n",
    "\n",
    "    if args.push_to_hub:\n",
    "        logger.info(f\"Pushing model and tokenizer to Hugging Face Hub: {args.hub_model_id}\")\n",
    "        trainer.push_to_hub(commit_message=\"End of training from notebook\")\n",
    "        logger.info(\"Model pushed to Hub successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.exception(f\"An error occurred during training: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

